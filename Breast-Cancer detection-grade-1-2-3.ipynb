{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7256da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification of breast cancer histopathological image using \n",
    "#convo-lutional neural networks into different grades in breast invasive duc-tal carcinoma (IDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d984ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c302a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc1252c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560c4b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset (training, testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aba079b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 792 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "rescale=1./255,\n",
    "shear_range=0.2,\n",
    "zoom_range=0.2,\n",
    "vertical_flip=True,horizontal_flip=True,\n",
    "rotation_range=90,\n",
    "height_shift_range=0.2,\n",
    "brightness_range=[0.1, 0.8])\n",
    "training_set = train_datagen.flow_from_directory(r'D:\\dataset-grade-1-2-3\\training-set',\n",
    "target_size=(150, 150),batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fafdfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 130 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "r'D:\\dataset-grade-1-2-3\\test-set',\n",
    "target_size=(150, 150),batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bda2c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builting CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86ebd0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeb42e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "009e1542",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32 ,kernel_size=3 , activation='relu',input_shape=[150,150,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030bbb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73679b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2) , strides=2 , padding='valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74035637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3cf9f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32 ,kernel_size=3 , activation='relu' ))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32 ,kernel_size=3 , activation='relu' ))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2) , strides=2 , padding='valid'))\n",
    "cnn.add(tf.keras.layers.Dropout(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a779a1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32 ,kernel_size=3 , activation='relu' ))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32 ,kernel_size=3 , activation='relu' ))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2) , strides=2 , padding='valid'))\n",
    "cnn.add(tf.keras.layers.Dropout(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a2a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ba5ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ea86c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8638469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128 , activation='relu' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce1c273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7b5e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=3 , activation='sigmoid' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593e1983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1930df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13d8deb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "25/25 [==============================] - 163s 6s/step - loss: 1.1099 - accuracy: 0.3535 - val_loss: 1.1867 - val_accuracy: 0.3231\n",
      "Epoch 2/24\n",
      "25/25 [==============================] - 144s 6s/step - loss: 1.0908 - accuracy: 0.4091 - val_loss: 1.1172 - val_accuracy: 0.3231\n",
      "Epoch 3/24\n",
      "25/25 [==============================] - 145s 6s/step - loss: 1.0888 - accuracy: 0.4091 - val_loss: 1.1004 - val_accuracy: 0.3231\n",
      "Epoch 4/24\n",
      "25/25 [==============================] - 150s 6s/step - loss: 1.0889 - accuracy: 0.4091 - val_loss: 1.1052 - val_accuracy: 0.3231\n",
      "Epoch 5/24\n",
      "25/25 [==============================] - 155s 6s/step - loss: 1.0867 - accuracy: 0.4091 - val_loss: 1.1226 - val_accuracy: 0.3231\n",
      "Epoch 6/24\n",
      "25/25 [==============================] - 145s 6s/step - loss: 1.0778 - accuracy: 0.4205 - val_loss: 1.0917 - val_accuracy: 0.3692\n",
      "Epoch 7/24\n",
      "25/25 [==============================] - 144s 6s/step - loss: 1.0724 - accuracy: 0.4419 - val_loss: 1.1146 - val_accuracy: 0.3462\n",
      "Epoch 8/24\n",
      "25/25 [==============================] - 146s 6s/step - loss: 1.0656 - accuracy: 0.4407 - val_loss: 1.1850 - val_accuracy: 0.3615\n",
      "Epoch 9/24\n",
      "25/25 [==============================] - 135s 5s/step - loss: 1.0954 - accuracy: 0.4003 - val_loss: 1.1131 - val_accuracy: 0.3231\n",
      "Epoch 10/24\n",
      "25/25 [==============================] - 128s 5s/step - loss: 1.0853 - accuracy: 0.4091 - val_loss: 1.3829 - val_accuracy: 0.3231\n",
      "Epoch 11/24\n",
      "25/25 [==============================] - 130s 5s/step - loss: 1.0857 - accuracy: 0.4091 - val_loss: 1.1193 - val_accuracy: 0.3231\n",
      "Epoch 12/24\n",
      "25/25 [==============================] - 129s 5s/step - loss: 1.0836 - accuracy: 0.4091 - val_loss: 1.1242 - val_accuracy: 0.3231\n",
      "Epoch 13/24\n",
      "25/25 [==============================] - 130s 5s/step - loss: 1.0860 - accuracy: 0.4091 - val_loss: 1.1344 - val_accuracy: 0.3231\n",
      "Epoch 14/24\n",
      "25/25 [==============================] - 129s 5s/step - loss: 1.0818 - accuracy: 0.4091 - val_loss: 1.1117 - val_accuracy: 0.3231\n",
      "Epoch 15/24\n",
      "25/25 [==============================] - 129s 5s/step - loss: 1.0791 - accuracy: 0.4091 - val_loss: 1.3668 - val_accuracy: 0.3231\n",
      "Epoch 16/24\n",
      "25/25 [==============================] - 107s 4s/step - loss: 1.0840 - accuracy: 0.4091 - val_loss: 1.1114 - val_accuracy: 0.3538\n",
      "Epoch 17/24\n",
      "25/25 [==============================] - 102s 4s/step - loss: 1.0682 - accuracy: 0.4280 - val_loss: 1.1602 - val_accuracy: 0.4000\n",
      "Epoch 18/24\n",
      "25/25 [==============================] - 96s 4s/step - loss: 1.0961 - accuracy: 0.3902 - val_loss: 1.1335 - val_accuracy: 0.3231\n",
      "Epoch 19/24\n",
      "25/25 [==============================] - 91s 4s/step - loss: 1.0773 - accuracy: 0.4167 - val_loss: 1.0882 - val_accuracy: 0.3538\n",
      "Epoch 20/24\n",
      "25/25 [==============================] - 92s 4s/step - loss: 1.0306 - accuracy: 0.4634 - val_loss: 1.6743 - val_accuracy: 0.3154\n",
      "Epoch 21/24\n",
      "25/25 [==============================] - 92s 4s/step - loss: 1.0970 - accuracy: 0.4091 - val_loss: 1.1891 - val_accuracy: 0.3231\n",
      "Epoch 22/24\n",
      "25/25 [==============================] - 93s 4s/step - loss: 1.0428 - accuracy: 0.4533 - val_loss: 1.8619 - val_accuracy: 0.3308\n",
      "Epoch 23/24\n",
      "25/25 [==============================] - 93s 4s/step - loss: 1.0479 - accuracy: 0.4533 - val_loss: 1.1455 - val_accuracy: 0.3846\n",
      "Epoch 24/24\n",
      "25/25 [==============================] - 95s 4s/step - loss: 1.0510 - accuracy: 0.4508 - val_loss: 1.2038 - val_accuracy: 0.3231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x172c5a2a6d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1173078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Single Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ce36923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 188ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = keras.utils.load_img(r'D:\\dataset-grade-1-2-3\\prediction\\grade-2.jpg', target_size=(150,150))\n",
    "test_image = keras.utils.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "937a4231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BC_IDC_Grade_1': 0, 'BC_IDC_Grade_2': 1, 'BC_IDC_Grade_3': 2}\n"
     ]
    }
   ],
   "source": [
    "print(training_set.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e0ea42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39913666 0.7560755  0.62182075]]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6e162dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "prediction = np.argmax(result[0], axis=0)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30b35afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade_2\n"
     ]
    }
   ],
   "source": [
    "if prediction == 0:\n",
    "    print(\"Grade_1\")\n",
    "elif prediction == 1:\n",
    "    print(\"Grade_2\")\n",
    "elif prediction == 2:\n",
    "    print(\"Grade_3\")\n",
    "else:\n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00df592d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c922a82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
